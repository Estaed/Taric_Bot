"""
Feature extraction module for Taric Bot AI.

This module combines all feature extraction modules to calculate advanced metrics
from state-action pairs generated by the frame analysis system.
"""

import os
import json
import glob
from pathlib import Path
import logging
import argparse
from tqdm import tqdm

from .combat_metrics import calculate_combat_metrics
from .vision_metrics import calculate_vision_metrics
from .positioning_metrics import calculate_positioning_metrics
from .mechanics_metrics import calculate_mechanics_metrics
from .game_state_metrics import calculate_game_state_metrics
from .file_organizer import organize_feature_files, organize_state_action_files

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def extract_features_from_file(file_path):
    """
    Extract all features from a single state-action pair file.
    
    Args:
        file_path (str): Path to the state-action pair JSON file
        
    Returns:
        dict: Dictionary of all extracted features
    """
    logger.info(f"Processing file: {file_path}")
    
    # Load state-action pair data
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # Extract metadata and match data
    metadata = data.get('metadata', {})
    match_data = data.get('match_data', {})
    state_action_pairs = data.get('state_action_pairs', [])
    
    # Calculate all features
    combat_metrics = calculate_combat_metrics(state_action_pairs, match_data)
    vision_metrics = calculate_vision_metrics(state_action_pairs, match_data)
    positioning_metrics = calculate_positioning_metrics(state_action_pairs, match_data)
    mechanics_metrics = calculate_mechanics_metrics(state_action_pairs, match_data)
    game_state_metrics = calculate_game_state_metrics(state_action_pairs, match_data)
    
    # Combine all features
    all_features = {
        'metadata': metadata,
        'match_id': metadata.get('match_id', ''),
        'features': {
            'combat': combat_metrics,
            'vision': vision_metrics,
            'positioning': positioning_metrics,
            'mechanics': mechanics_metrics,
            'game_state': game_state_metrics
        }
    }
    
    return all_features


def extract_features_from_directory(input_dir, output_dir, organize_files=True):
    """
    Extract features from all state-action pair files in a directory.
    
    Args:
        input_dir (str): Directory containing state-action pair JSON files
        output_dir (str): Directory to save extracted features
        organize_files (bool): Whether to organize output files
        
    Returns:
        int: Number of files processed
    """
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Find all state-action pair files
    sa_files = glob.glob(os.path.join(input_dir, 'taric_sa_pairs_*.json'))
    logger.info(f"Found {len(sa_files)} state-action pair files to process")
    
    # Process each file
    processed_count = 0
    for file_path in tqdm(sa_files, desc="Extracting features"):
        try:
            # Extract features
            features = extract_features_from_file(file_path)
            
            # Generate output filename
            match_id = features['match_id']
            output_file = os.path.join(output_dir, f"taric_features_{match_id}.json")
            
            # Save features to file
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(features, f, indent=2)
            
            processed_count += 1
            
        except Exception as e:
            logger.error(f"Error processing {file_path}: {str(e)}")
    
    # Organize output files if requested
    if organize_files and processed_count > 0:
        logger.info("Organizing extracted feature files...")
        organize_feature_files(output_dir)
    
    logger.info(f"Processed {processed_count} files successfully")
    return processed_count


def batch_process_features(input_dir, output_dir, batch_size=10, organize_files=True):
    """
    Process state-action pairs in batches to save memory.
    
    Args:
        input_dir (str): Directory containing state-action pair JSON files
        output_dir (str): Directory to save extracted features
        batch_size (int): Number of files to process in each batch
        organize_files (bool): Whether to organize output files
        
    Returns:
        int: Number of files processed
    """
    # Create output directory if it doesn't exist
    os.makedirs(output_dir, exist_ok=True)
    
    # Find all state-action pair files
    sa_files = glob.glob(os.path.join(input_dir, 'taric_sa_pairs_*.json'))
    logger.info(f"Found {len(sa_files)} state-action pair files to process")
    
    # Process files in batches
    total_processed = 0
    for i in range(0, len(sa_files), batch_size):
        batch_files = sa_files[i:i+batch_size]
        logger.info(f"Processing batch {i//batch_size + 1}/{(len(sa_files)-1)//batch_size + 1}")
        
        for file_path in tqdm(batch_files, desc=f"Batch {i//batch_size + 1}"):
            try:
                # Extract features
                features = extract_features_from_file(file_path)
                
                # Generate output filename
                match_id = features['match_id']
                output_file = os.path.join(output_dir, f"taric_features_{match_id}.json")
                
                # Save features to file
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(features, f, indent=2)
                
                total_processed += 1
                
            except Exception as e:
                logger.error(f"Error processing {file_path}: {str(e)}")
    
    # Organize output files if requested
    if organize_files and total_processed > 0:
        logger.info("Organizing extracted feature files...")
        organize_feature_files(output_dir)
    
    logger.info(f"Processed {total_processed} files successfully")
    return total_processed


def merge_features(features_dir, output_file):
    """
    Merge all feature files into a single consolidated file.
    
    Args:
        features_dir (str): Directory containing feature JSON files
        output_file (str): Path to save the merged features file
        
    Returns:
        int: Number of feature files merged
    """
    # Find all feature files
    feature_files = glob.glob(os.path.join(features_dir, '**', 'taric_features_*.json'), recursive=True)
    logger.info(f"Found {len(feature_files)} feature files to merge")
    
    # Initialize merged data structure
    merged_data = {
        'metadata': {
            'source_files': len(feature_files),
            'feature_count': 0
        },
        'features': []
    }
    
    # Process each file
    for file_path in tqdm(feature_files, desc="Merging features"):
        try:
            # Load features
            with open(file_path, 'r', encoding='utf-8') as f:
                features = json.load(f)
            
            # Add to merged data
            merged_data['features'].append({
                'match_id': features.get('match_id', ''),
                'metadata': features.get('metadata', {}),
                'features': features.get('features', {})
            })
            
            merged_data['metadata']['feature_count'] += 1
            
        except Exception as e:
            logger.error(f"Error merging {file_path}: {str(e)}")
    
    # Save merged data
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(merged_data, f, indent=2)
    
    logger.info(f"Merged {merged_data['metadata']['feature_count']} feature files successfully")
    return merged_data['metadata']['feature_count']


def main():
    """
    Command-line interface for feature extraction.
    """
    parser = argparse.ArgumentParser(description='Extract features from Taric state-action pairs')
    parser.add_argument('--input-dir', required=True, help='Directory containing state-action pair JSON files')
    parser.add_argument('--output-dir', required=True, help='Directory to save extracted features')
    parser.add_argument('--batch-size', type=int, default=10, help='Number of files to process in each batch')
    parser.add_argument('--merge', action='store_true', help='Merge all feature files into a single file')
    parser.add_argument('--merged-output', help='Path to save the merged features file')
    parser.add_argument('--organize-input', action='store_true', help='Organize input files before processing')
    parser.add_argument('--no-organize-output', action='store_false', dest='organize_output', 
                        help='Skip organizing output files after processing')
    parser.set_defaults(organize_output=True)
    
    args = parser.parse_args()
    
    # Organize input files if requested
    if args.organize_input and os.path.isdir(args.input_dir):
        logger.info("Organizing input state-action pair files...")
        organize_state_action_files(args.input_dir)
    
    # Process features
    if os.path.isdir(args.input_dir):
        batch_process_features(args.input_dir, args.output_dir, args.batch_size, organize_files=args.organize_output)
    else:
        logger.error(f"Input directory not found: {args.input_dir}")
        return
    
    # Merge features if requested
    if args.merge:
        merged_output = args.merged_output or os.path.join(args.output_dir, 'taric_features_merged.json')
        merge_features(args.output_dir, merged_output)


if __name__ == "__main__":
    main() 